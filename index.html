---
layout: post
title: Blogging Like a Hacker
---

<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="CSCE625 : ">

      <!-- Lightbox -->
      <script src="plugins/lightbox/js/jquery-1.11.0.min.js"></script>
      <script src="plugins/lightbox/js/lightbox.min.js"></script>      
      
      <link href="plugins/lightbox/css/lightbox.css" rel="stylesheet" />
      
        <!-- MathJax -->
        <script type="text/javascript"
                src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
            });
        </script>
      
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>CSCE 625 Final Project: Face Alignment</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/phg1024/CSCE625/tree/master/finalproject">View on GitHub</a>

          <h1 id="project_title">CSCE 625 Final Project</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/phg1024/CSCE625/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/phg1024/CSCE625/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
          
        <!-- Introduction -->
        <h3><a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h3>
        <p>Face alignment is the task of finding a semantic face shape from an image of human face. The face shape can be defined as a shape vector $S = \{\mathbf p_1, \mathbf p_2, \ldots, \mathbf p_n\}$ containing $n$ semantically interesting spots, i.e. landmarks, such as eye corners, nose tip, mouth corners and face contour, etc.</p>
        <div class="imagebox">
        <a href="images/landmarks.jpg" data-lightbox="landmarks" data-title="A face shape with 68 landmarks."><img id="fig_landmarks" src="images/landmarks.jpg" width="360px"></img></a><br>
        <p class="imagetitle"><strong>Figure 1.</strong> A face shape with 68 landmarks.</p>
        </div>
          <p>Numerous methods have been proposed for face alignment, most of which can be classified into either <em>optimization-based</em> techniques, such as <a href="http://en.wikipedia.org/wiki/Active_appearance_model">Active Appearance Model</a>, or <em>regression-based</em> techniques such as <a href="http://dx.doi.org/10.1007/s11263-013-0667-3">Explicit Shape Regression</a>.</p>
          <p>In this project, a regression based face alignment algorithm, <a href="http://dx.doi.org/10.1007/s11263-013-0667-3">Face Alignment by Explicit Shape Regression</a>, is implemented. This algorithm is one of the state-of-the-art techniques for face alignment that has both high precision and good running time performance.</p>
        
        <!-- Algorithm Outline -->
        <h3><a id="outline" class="anchor" href="#outline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Algorithm Outline</h3>
        <p>
        The explicit shape regression (ESR) algorithm generates face shape by repeatedly refining an initial guess shape via a series of cascaded regression functions. The refinement using a regression function $R$ is called a stage, and there are in total $T$ stages. In each stage $t$, the output of the previous stage, $S^{t-1}$, together with the input image $I$ are used to predict a difference shape $\Delta S^t$. The sum of the difference shape and the current guess shape is the output of stage $t$, i.e.</p>
        \[S^t = S^{t-1} + R^{t-1}(I, S^{t-1})\]
        where $t\in[1..T]$ is the stage index.
    
        <p>In each stage, the regression function is computed by minimizing the following error function:
            \[R^t = \arg\min_R\sum_{i=1}^N\|\hat S_i - (S_i^{t-1}+R(I_i, S_i^{t-1}))\|^2\]
        where $N$ is the number of training samples.
        </p>
        <p>The regression functions are represented by a series of weak regressors, i.e.
            \[R^t = (r_1, r_2, \ldots, r_k)\]
        where each $r_j$ is called a primitive regressor. In each stage, the input shape is refined by all the primitive regressors in a cascaded manner: $k$ primitive regressors form a chain of regressors, where each primitive regressor is called a level. The level $k$ regressor takes the output shape of previous level as input and predict a delta shape vector to refine the input shape vector. The refined shape vector is then passed to the next level of regressor for further refinement.
        </p>
        <p>Typically hundreds of primitive regressors are used in each stage. The primitive regressors are weak regressors because they are only able to reduce the shape error slightly, therefore a series of many primitive regressors are needed in each stage. That said, each primitive regressor alone is not able to reduce the shape error much, but all the primitive regressors collectively are able to reduce the shape error significantly. With enough number of primitive regressors, the final regression function becomes very powerful.
        </p>
        <div class="imagebox">
            <a href="images/regressor.png" data-lightbox="regressor" data-title="Illustration of the regression function."><img id="fig_regressor" src="images/regressor.png" width="240px"></img></a><br>
        <p class="imagetitle"><strong>Figure 2.</strong> Illustration of the regression function. A regressor function has $n$ stages, and each stage contains $k$ primitive regressors. The guess shape is refined by all primitive regressors in a cascaded manner.</p>
        </div>
        <p>Ferns are chosen as the primitive regressors. A fern is a classification based regressor that takes an $F$ dimensional input feature vector and computes an output vector by classifiy the input into one of the $2^F$ bins. The classification is performed by comparing the input feature vector to $F$ thresholds of the fern. The classification result is an $F$ dimensional binary vector $\mathbf f = (f_1, f_2, \ldots, f_F)$ such that $f_i = 0$ if the $i$th attribute greater than the corresponding threshold and $f_i = 1$ otherwise. The output of the regressor is determined by looking up the output entry for the classification vector.        
        </p>
        <p>The output vector for each bin of a fern is computed as
            \[\delta S_b = \arg\min_{\delta S}\sum_{i\in \Omega_b}\|\hat S_i - (S_i+\delta S)\|\]
        where $\Omega_b$ is the set of training samples in bin $b$. This gives the following equation of computing the fern output:
            \[\delta S_b = \frac{\sum_{i\in\Omega_b}(\hat S_i - S_i)}{|\Omega_b|}\]
            A shrinkage parameter $\beta$ is added to the above equation to overcome over-fitting when the number of training samples in a bin is too small:
            \[\delta S_b = \frac{1}{1+\beta |\Omega_b|}\frac{\sum_{i\in\Omega_b}(\hat S_i - S_i)}{|\Omega_b|}\]
        </p>
        <!-- Implementation Detail -->
        <h3><a id="detail" class="anchor" href="#outline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation Details</h3>
        <h4>Face Detection</h4><p>The first step of face alignment is to detect face in input images. This is done by using <a href="http://docs.opencv.org/trunk/doc/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html">OpenCV face detector</a>. The detector returns a list of bounding boxes of potential face regions, in which the initial guess face shapes are placed.</p>
        <h4>Face Region Scaling</h4>
        <p>The input images are scaled according to the detected face regions. The scaling is necessary for achieving stable results because the shape indexed features are sampled directly from input images using given shape indexed locations. Larger face shapes are thus more prone to pixel noise in the images. Scaling the images to make sure the faces in all training samples have similar size reduces the undesired noise. In my implementation, the images are scaled such that the size of detected face region is 128x128.</p>
        <h4>Training Data</h4>
        <p>The data used for training is available <a href="http://ibug.doc.ic.ac.uk/resources">here</a>. It is a combination of the widely used <a href="http://vis-www.cs.umass.edu/lfw/">LFW dataset</a>, <a href="http://neerajkumar.org/databases/lfpw/">LFPW dataset</a> and <a href="http://www.ifp.illinois.edu/~vuongle2/helen/">Helen dataset</a>. All images are annotated with 68 landmarks illustrated in <a href="#fig_landmarks">Figure. 1</a></p>
        <h4>Face Alignment Procedure</h4>
        While applying the trained model for face alignment, a random shape vector is chosen from  a database of face shapes as initial guess. Since the output of the algorithm is a refinement of the input shape, the quality of the initial guess would inevitably affect the alignment output. To remove the effect of this randomness, multiple initial shapes are used simultaneously and the final shape is computed as a combination of all outputs. Cao et al suggested 5 initial shapes would produce good result in most cases, however, more initial shapes are needed in my experiment.
        <!-- Results -->
        <h3><a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results and Analysis</h3>   
        <h4>Performance Summary</h4>
        The algorithm is tested with the test data obtain from the same source as training data. The error of the test cases is measured as the mean distance between the output shape vector and the ground truth shape. To obtain a shape invariant measure, the error is normalized by the distance between two pupils of the ground truth shape. For the test data with 507 images, the average normalized error in the test data set is 0.0581, which is comparable to the results reported in <a href="#paper_cao2013ijcv">[2]</a>. The cumulative error curve of the test data set is shown in <a href="#fig_cdf">Figure 3</a>. Note that the relative error is below 0.1 in more than 90% percent of all test cases, and below 0.05 in about 50% of all test cases.
        <div id="fig_cdf" class="imagebox"><a href="images/error_dist.png" data-lightbox="error_dist" data-title="Error distribution."><img src="images/error_dist.png" width="480px"></a><br>
            <p class="imagetitle"><strong>Figure 3.</strong> Cumulative error curve of the test data.</p>
        </div>
        A brief analysis on the results reveals that the error mainly come from contour points, i.e. point 1 ~ 17. <a href="#fig_girl_error">Figure 4</a> shows a typical error curve of a single output shape vector. Note the error for the first 17 points are larger than other points.
        <div id="fig_girl_error" class="imagebox"><a href="images/error_girl.png" data-lightbox="error_girl" data-title="Error curve of a single output shape vector."><img src="images/error_girl.png" width="480px"></a><br>
            <p class="imagetitle"><strong>Figure 4.</strong> Error curve of a single output shape vector. <a href="#fig_girl">Figure 5</a> visualize this shape and corresponding ground truth shape.</p>
        </div>
        <div id="fig_girl" class="imagebox"><a href="images/girl.png" data-lightbox="girl" data-title="A comparison between output shape and ground truth shape."><img src="images/girl.png" width="480px"></a><br>
            <p class="imagetitle"><strong>Figure 5.</strong> Comparison of output shape (green) and ground truth shape (red).</p>
        </div>      
      
        <h4>Successful Cases</h4>
        For most images with frontal face and neutral expression, the algorithm works very well. Below are 4 successful cases from the test data. Note the head poses and expressions vary among these images.
        <div>
        <table width="90%" left="5%" text-align="center">
            <tr>
                <td width="25%"><a href="images/succeeded/0008.png" data-lightbox="input0008" data-title="Input 0008."><img src="images/succeeded/0008.png" width="120px"></a></td>
                <td width="25%"><a href="images/succeeded/0020.png" data-lightbox="input0020" data-title="Input 0020."><img src="images/succeeded/0020.png" width="120px"></a></td>
                <td width="25%"><a href="images/succeeded/0039.png" data-lightbox="input0039" data-title="Input 0039."><img src="images/succeeded/0039.png" width="120px"></a></td>
                <td width="25%"><a href="images/succeeded/0058.png" data-lightbox="input0058" data-title="Input 0058."><img src="images/succeeded/0058.png" width="120px"></a></td>
            </tr>
            <tr>
                <td width="25%"><a href="images/succeeded/aligned_0008.png" data-lightbox="result0008" data-title="Result 0008."><img src="images/succeeded/aligned_0008.png" width="120px"></a></td>
                <td width="25%"><a href="images/succeeded/aligned_0020.png" data-lightbox="result0020" data-title="Result 0020."><img src="images/succeeded/aligned_0020.png" width="120px"></a></td>
                <td width="25%"><a href="images/succeeded/aligned_0039.png" data-lightbox="result0039" data-title="Result 0039."><img src="images/succeeded/aligned_0039.png" width="120px"></a></td>
                <td width="25%"><a href="images/succeeded/aligned_0058.png" data-lightbox="result0058" data-title="Result 0058."><img src="images/succeeded/aligned_0058.png" width="120px"></a></td>
            </tr>   
            <tr>
                <td>Succeeded case 1</td>
                <td>Succeeded case 2</td>
                <td>Succeeded case 3</td>
                <td>Succeeded case 4</td>
            </tr>            
        </table>
        </div>
        
        <h4>Failed Cases</h4>
        For images with side face or large expression (mostly laugh), the alignment error is much larger. The failure usually occurs in image with occlusion (case 1 and 4), extreme expression (case 2), or extreme lighting conditions (case 3).
        <div>
        <table width="90%" left="5%" text-align="center">
            <tr>
                <td width="25%"><a href="images/failed/0005.png" data-lightbox="input0005" data-title="Input 0005."><img src="images/failed/0005.png" width="120px"></a></td>
                <td width="25%"><a href="images/failed/0007.png" data-lightbox="input0007" data-title="Input 0007."><img src="images/failed/0007.png" width="120px"></a></td>
                <td width="25%"><a href="images/failed/0053.png" data-lightbox="input0053" data-title="Input 0053."><img src="images/failed/0053.png" width="120px"></a></td>
                <td width="25%"><a href="images/failed/0065.jpg" data-lightbox="input0065" data-title="Input 0065."><img src="images/failed/0065.jpg" width="120px"></a></td>
            </tr>
            <tr>
                <td width="25%"><a href="images/failed/aligned_0005.png" data-lightbox="result0005" data-title="Result 0005."><img src="images/failed/aligned_0005.png" width="120px"></a></td>
                <td width="25%"><a href="images/failed/aligned_0007.png" data-lightbox="result0007" data-title="Result 0007."><img src="images/failed/aligned_0007.png" width="120px"></a></td>
                <td width="25%"><a href="images/failed/aligned_0053.png" data-lightbox="result0053" data-title="Result 0053."><img src="images/failed/aligned_0053.png" width="120px"></a></td>
                <td width="25%"><a href="images/failed/aligned_0065.jpg" data-lightbox="result0065" data-title="Result 0065."><img src="images/failed/aligned_0065.jpg" width="120px"></a></td>
            </tr>      
            <tr>
                <td>Failed case 1</td>
                <td>Failed case 2</td>
                <td>Failed case 3</td>
                <td>Failed case 4</td>
            </tr>
        </table>
        </div>
      
        <h4>Gallery</h4>
        Please follow this <a href="results.html">link</a> to a gallery of results.
        <h3></h3>
          
        <h3><a id="Usage" class="anchor" href="#usage" aria-hidden="true"><span class="octicon octicon-link"></span></a>Usage</h3>
          <p>To find the face shape of an image, download the MATALB source code <a href="https://github.com/phg1024/CSCE625/tree/master/finalproject">here</a>, then run the following script with the <a href="https://www.dropbox.com/s/odmf7ko1lmjk8r8/model.mat?dl=0">provided model file</a> in MATLAB:</p>

{% highlight matlab %}
model = load('model.mat');
[filename, pathname] = uigetfile({'*.jpg; *.png; *.gif; *.bmp'; '*.*'}, ...
                                 'Choose Image');
img = imread([pathname, filename]);
[box, points, succeeded] = applyModel(img, model);
if succeeded
    figure;showImageWithPoints(img, box, points);
end
{% endhighlight %}
          <p>Note that you need to run the above script in the folder where you put the downloaded source code</p>
          <h3><a id="Usage" class="anchor" href="#usage" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h3>
          <ol>
              <li id="paper_cao2012cvpr">Xudong Cao, Yichen Wei, Fang Wen, Jian Sun. <em><a href="http://research.microsoft.com/pubs/192097/cvpr12_facealignment.pdf">Face Alignment by Explicit Shape Regression.</a></em> In CVPR 2012.</li>
              <li id="paper_cao2013ijcv">Xudong Cao, Yichen Wei, Fang Wen, Jian Sun. <em><a href="http://dx.doi.org/10.1007/s11263-013-0667-3">Face Alignment by Explicit Shape Regression.</a></em> International Journal of Computer Vision (IJCV), Volume 107, Number 2, pages 177-190.</li>
          </ol>


<h3><a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Author Information</h3>

<p>This program is written by <a href="https://github.com/phg1024" class="user-mention">@Peihong</a> for the final project in <a href="http://robotics.cs.tamu.edu/dshell/cs625/">CSCE 625 Artificial Intelligence</a> course in Fall 2014.</p>

<p>Please contact the author if you find any error/bug in the code.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">CSCE625 Final Project Page maintained by <a href="https://github.com/phg1024">phg1024</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
